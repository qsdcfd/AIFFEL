{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recognized-floor",
   "metadata": {},
   "source": [
    "# 프로젝트 핵심\n",
    "이번 프로젝트는 세 가지의 경우를 주었습니다. 각 세 가지의 경우에 따라서 어떤 모델은 성능이 좋고 어떤 모델은 좋지 않습니다. 그것은 아무래도 각 모델이 갖고 있는 장단점 그로 인한 활용도 차이라고 생각합니다. 이번 프로젝트를 통해서 적재적소에 맞는 모델을 알 수 있는 좋은 기회라고 생각합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-execution",
   "metadata": {},
   "source": [
    "# load_digits프로젝트의 성능 좋은 모델 찾으러 가는 과정의 첫 단계\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-focus",
   "metadata": {},
   "source": [
    "load_digits프로젝트에 맞는 모델은 무엇일까 찾는 과정입니다.\n",
    "digits는 이미지 파일이라고 생각이 됩니다. 이미지 파일은 2차원 배열이다.\n",
    "2차원 배열에서 가장 좋은 성능은 낼 수 있는 모델은\n",
    "Decision Tree,RandomForest,SVM,SGD,Logistics Regression 모델 중에서\n",
    "SVM이라고 생각합니다. 그 이유는 한 차원을 늘려서 data를 클러스팅하면 좋은 결과를 얻기 때문입니다.\n",
    "이미지 파일이라서 정규화를 시도했습니다\n",
    "Recall값으로 성능 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "higher-russian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        38\n",
      "           1       0.75      0.83      0.79        36\n",
      "           2       0.75      0.84      0.79        32\n",
      "           3       0.92      0.86      0.89        56\n",
      "           4       0.85      0.90      0.88        31\n",
      "           5       0.92      0.97      0.95        36\n",
      "           6       0.97      0.94      0.96        34\n",
      "           7       0.94      0.88      0.91        34\n",
      "           8       0.88      0.78      0.82        27\n",
      "           9       0.79      0.83      0.81        36\n",
      "\n",
      "    accuracy                           0.88       360\n",
      "   macro avg       0.88      0.87      0.87       360\n",
      "weighted avg       0.88      0.88      0.88       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.97      1.00      0.98        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.96      0.89      0.92        27\n",
      "           9       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      0.89      0.94        36\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       1.00      0.91      0.95        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.97      0.94      0.96        36\n",
      "           6       0.94      1.00      0.97        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.72      0.96      0.83        27\n",
      "           9       0.92      0.94      0.93        36\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.95       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        38\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.96      0.98        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.92      0.94      0.93        36\n",
      "           6       0.97      1.00      0.99        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.92      0.89      0.91        27\n",
      "           9       0.92      1.00      0.96        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Decision Tree       : 0.875\n",
      "Random Forest       : 0.9861111111111112\n",
      "SVM                 : 0.9944444444444445\n",
      "SGD                 : 0.9555555555555556\n",
      "Logistic Regression : 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "\n",
    "# (2) 데이터 준비\n",
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=32)\n",
    "\n",
    "# 정규화\n",
    "x_train_norm, x_test_norm = x_train / np.max(x_train), x_test / np.max(x_test)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(x_train_norm, y_train)\n",
    "decision_tree_y_pred = decision_tree.predict(x_test_norm)\n",
    "print(classification_report(y_test, decision_tree_y_pred))\n",
    "\n",
    "# RandomForest\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train_norm, y_train)\n",
    "random_forest_y_pred = random_forest.predict(x_test_norm)\n",
    "print(classification_report(y_test, random_forest_y_pred))\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train_norm, y_train)\n",
    "svm_y_pred = svm_model.predict(x_test_norm)\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier(shuffle=False)\n",
    "sgd_model.fit(x_train_norm, y_train)\n",
    "sgd_y_pred = sgd_model.predict(x_test_norm)\n",
    "print(classification_report(y_test, sgd_y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=256)\n",
    "logistic_model.fit(x_train_norm, y_train)\n",
    "logistic_y_pred = logistic_model.predict(x_test_norm)\n",
    "print(classification_report(y_test, logistic_y_pred))\n",
    "  \n",
    "print('Decision Tree       : {}'.format(recall_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "print('Random Forest       : {}'.format(recall_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "print('SVM                 : {}'.format(recall_score(y_test, svm_y_pred, average='weighted')))\n",
    "print('SGD                 : {}'.format(recall_score(y_test, sgd_y_pred, average='weighted')))\n",
    "print('Logistic Regression : {}'.format(recall_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-richards",
   "metadata": {},
   "source": [
    "## 정규화를 하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "altered-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        38\n",
      "           1       0.75      0.83      0.79        36\n",
      "           2       0.75      0.84      0.79        32\n",
      "           3       0.92      0.86      0.89        56\n",
      "           4       0.85      0.90      0.88        31\n",
      "           5       0.92      0.97      0.95        36\n",
      "           6       0.97      0.94      0.96        34\n",
      "           7       0.94      0.88      0.91        34\n",
      "           8       0.88      0.78      0.82        27\n",
      "           9       0.79      0.83      0.81        36\n",
      "\n",
      "    accuracy                           0.88       360\n",
      "   macro avg       0.88      0.87      0.87       360\n",
      "weighted avg       0.88      0.88      0.88       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.97      1.00      0.98        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.96      0.89      0.92        27\n",
      "           9       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.97      0.92      0.94        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.98      0.96      0.97        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.92      0.97      0.95        36\n",
      "           6       0.94      1.00      0.97        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.96      0.93      0.94        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        38\n",
      "           1       0.97      0.97      0.97        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.98      0.98      0.98        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.94      0.92      0.93        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      0.94      0.97        34\n",
      "           8       0.93      1.00      0.96        27\n",
      "           9       0.88      0.97      0.92        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Decision Tree       : 0.875\n",
      "Random Forest       : 0.9861111111111112\n",
      "SVM                 : 0.9944444444444445\n",
      "SGD                 : 0.9722222222222222\n",
      "Logistic Regression : 0.9694444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "# (2) 데이터 준비\n",
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=32)\n",
    "\n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "decision_tree_y_pred = decision_tree.predict(x_test)\n",
    "print(classification_report(y_test, decision_tree_y_pred))\n",
    "\n",
    "# RandomForest\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train, y_train)\n",
    "random_forest_y_pred = random_forest.predict(x_test)\n",
    "print(classification_report(y_test, random_forest_y_pred))\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier(shuffle=False)\n",
    "sgd_model.fit(x_train, y_train)\n",
    "sgd_y_pred = sgd_model.predict(x_test)\n",
    "print(classification_report(y_test, sgd_y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=256)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(x_test)\n",
    "print(classification_report(y_test, logistic_y_pred))\n",
    "  \n",
    "print('Decision Tree       : {}'.format(recall_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "print('Random Forest       : {}'.format(recall_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "print('SVM                 : {}'.format(recall_score(y_test, svm_y_pred, average='weighted')))\n",
    "print('SGD                 : {}'.format(recall_score(y_test, sgd_y_pred, average='weighted')))\n",
    "print('Logistic Regression : {}'.format(recall_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-salem",
   "metadata": {},
   "source": [
    "# 결과회고\n",
    "\n",
    "예상대로 SVM이 가장 좋았습니다.\n",
    "정규화를 한 것과 하지 않은 것의 결과로는\n",
    "Decision Tree 와 Random Forest 와 SVM은 정확성의 차이가 없지만\n",
    "SGD와 Logistic Regression경우 정확성이 감소한 것을 볼 수 있습니다.\n",
    "왜 그럴까요?\n",
    "precision 과 recall이 떨어지면 정확성도 떨어진다고 합니다(by오차행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-breakfast",
   "metadata": {},
   "source": [
    "\n",
    "# load_wine:와인 프로젝트의 성능 좋은 모델 찾으러 가는 과정의 첫 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-screw",
   "metadata": {},
   "source": [
    "와인은 처음 실습한 붓꽃 품종 분류문제처럼 여러가지 특징에 따라 종류가 나눠지는 것으로 알고 있습니다. 그래서 Decision Tree,RandomForest,SVM,SGD,Logistics Regression 모델 중에서 Decision Tree 아니면 RandomForest가 성능이 가장 좋을 것이라고 예상이 되나 코딩을 해봐야 할 것 같고요 아마 Decision Tree의 단점을 메꾼 RandomForest가 조금 더 낫지 않을까 싶습니다.\n",
    "\n",
    "그리고 Recall 값 비교를 통해 정확한 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rubber-image",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.50      1.00      0.67        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.50      0.43      0.37        36\n",
      "weighted avg       0.43      0.53      0.40        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "Decision Tree       : 0.9444444444444444\n",
      "Random Forest       : 1.0\n",
      "SVM                 : 0.6111111111111112\n",
      "SGD                 : 0.5277777777777778\n",
      "Logistic Regression : 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import세팅하기\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# (2) 데이터 준비하기\n",
    "wines = load_wine()\n",
    "wines_data = wines.data\n",
    "wines_label = wines.target\n",
    "\n",
    "# (3) train, test 데이터 분리하기\n",
    "x_train, x_test, y_train, y_test = train_test_split(wines_data, \n",
    "                                                    wines_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 5가지 모델 학습 및 예측\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "decision_tree_y_pred = decision_tree.predict(x_test)\n",
    "print(classification_report(y_test, decision_tree_y_pred))\n",
    "\n",
    "# RandomForest\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train, y_train)\n",
    "random_forest_y_pred = random_forest.predict(x_test)\n",
    "print(classification_report(y_test, random_forest_y_pred))\n",
    "\n",
    "# SVM\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(x_train, y_train)\n",
    "svm_y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "# SGD\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(x_train, y_train)\n",
    "sgd_y_pred = sgd_model.predict(x_test)\n",
    "print(classification_report(y_test, sgd_y_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=4096)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(x_test)\n",
    "print(classification_report(y_test, logistic_y_pred))\n",
    "\n",
    "print('Decision Tree       : {}'.format(recall_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "print('Random Forest       : {}'.format(recall_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "print('SVM                 : {}'.format(recall_score(y_test, svm_y_pred, average='weighted')))\n",
    "print('SGD                 : {}'.format(recall_score(y_test, sgd_y_pred, average='weighted')))\n",
    "print('Logistic Regression : {}'.format(recall_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-botswana",
   "metadata": {},
   "source": [
    "# 결과 회고\n",
    "예상대로  Decision Tree 와 Random Forest가 우수한 성능을 보여줬고 그 중에서 Random Forest가 가장 높은 성능을 보유했다. 그 이유는 확실하게 구분을 할 수 있는 Random Forest의 장점때문인 것 같습니다. \n",
    "근데 왜 Logistic Regression이 높은 성능을 보였는지는 생각하고 더 공부를 해야할 것 같습니다. 왜냐하면 와인이 단순하게 이진분류가 가능한지가 의문이기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-fields",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "future-sword",
   "metadata": {},
   "source": [
    "# load_breast_cancer : 유방암 프로젝트의 성능 좋은 모델 찾으러 가는 과정의 첫 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-gateway",
   "metadata": {},
   "source": [
    "사실 유방암의 경우는 음성/양성으로 이진 분류가 가능하기 때문에 Logistic Regression이 좋은 성능을 보일거고 더군다나 유방암은 LMS에섣 보았듯이 features의 개수가 많이 있었습니다. 그러므로 features가 많을 때 좋은 성능을 낼 수 있는 모델은 Decison Tree 와 Random Forest들이 우수한 성능을 낼 것이지만 이 중에서 발전되고 단점을 보완한 Random Forest가 가장 높을 것 같습니다. \n",
    "그리고 위랑 다르게 이번에는 양성을 양성답게 음성을 음성답게 판단하는 것이 가장 중요하므로 정확성을 기준으로 판단해야할 것 같습니다 오진률을 낮춰야하기 때문이죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demanding-administrator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        40\n",
      "           1       0.76      1.00      0.86        74\n",
      "\n",
      "    accuracy                           0.79       114\n",
      "   macro avg       0.88      0.70      0.72       114\n",
      "weighted avg       0.84      0.79      0.76       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Decision Tree       : 0.9122807017543859\n",
      "Random Forest       : 1.0\n",
      "SVM                 : 0.9035087719298246\n",
      "SGD                 : 0.7894736842105263\n",
      "Logistic Regression : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "  # (1) 필요한 모듈 import 세팅하기\n",
    "  from sklearn.datasets import load_breast_cancer\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn import svm\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.metrics import classification_report\n",
    "  from sklearn.metrics import recall_score\n",
    "\n",
    "  # (2) 데이터 준비하기\n",
    "  breast_cancer = load_breast_cancer()\n",
    "  breast_cancer_data = breast_cancer.data\n",
    "  breast_cancer_label = breast_cancer.target\n",
    "\n",
    "  # (3) train, test 데이터 분리하기\n",
    "  x_train, x_test, y_train, y_test = train_test_split(breast_cancer_data, \n",
    "                                                      breast_cancer_label, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=7)\n",
    "\n",
    "  # (4) 5가지 모델 학습 및 예측하기\n",
    "  # Decision Tree\n",
    "  decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "  decision_tree.fit(x_train, y_train)\n",
    "  decision_tree_y_pred = decision_tree.predict(x_test)\n",
    "  print(classification_report(y_test, decision_tree_y_pred))\n",
    "\n",
    "  # RandomForest\n",
    "  random_forest = RandomForestClassifier(random_state=32)\n",
    "  random_forest.fit(x_train, y_train)\n",
    "  random_forest_y_pred = random_forest.predict(x_test)\n",
    "  print(classification_report(y_test, random_forest_y_pred))\n",
    "\n",
    "  # SVM\n",
    "  svm_model = svm.SVC()\n",
    "  svm_model.fit(x_train, y_train)\n",
    "  svm_y_pred = svm_model.predict(x_test)\n",
    "  print(classification_report(y_test, svm_y_pred))\n",
    "\n",
    "  # SGD\n",
    "  sgd_model = SGDClassifier()\n",
    "  sgd_model.fit(x_train, y_train)\n",
    "  sgd_y_pred = sgd_model.predict(x_test)\n",
    "  print(classification_report(y_test, sgd_y_pred))\n",
    "\n",
    "  # Logistic Regression\n",
    "  logistic_model = LogisticRegression(max_iter=4096)\n",
    "  logistic_model.fit(x_train, y_train)\n",
    "  logistic_y_pred = logistic_model.predict(x_test)\n",
    "  print(classification_report(y_test, logistic_y_pred))\n",
    "  print('Decision Tree       : {}'.format(recall_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "  print('Random Forest       : {}'.format(recall_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "  print('SVM                 : {}'.format(recall_score(y_test, svm_y_pred, average='weighted')))\n",
    "  print('SGD                 : {}'.format(recall_score(y_test, sgd_y_pred, average='weighted')))\n",
    "  print('Logistic Regression : {}'.format(recall_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-greenhouse",
   "metadata": {},
   "source": [
    "# 결과 회고\n",
    "예상 대로 Random Forest가 가장 우수한 성능을 보였습니다. 그 이유는 \n",
    "feature의 종류가 많으면 많을 수록 이진 분류 문제의 정확도를 높여준다는 성질 때문입니다. 그렇기에 Logisitc Regression또한 좋은 성능을 보였던 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-record",
   "metadata": {},
   "source": [
    "# 프로젝트 회고\n",
    "\n",
    "그저 글로만 LMS나 여러 사이트를 보면 이해는 갈 때도 있고 헷갈릴 때도 있었으나 막상 프로젝트를 구현을 해보니 왜 이 프로젝트에는 이 모델이 적합할 수 밖에 없는 이유를 명확하게 알게 되어서 좋았습니다. 그로 인해 \n",
    "feature의 갯수가 많은 것은 Decision Tree나 Random Forest를\n",
    "이진 분류가 잘되는 것은 Logistic Regression을\n",
    "차원을 늘려서 결과를 낼 때는 SVM이용해야 한다는 이 사실들이 재미있었고 이제 스스로 여기엔 나오지 못한 SGD모델이 쓰이는 예시를 찾으러 가야할 것 같습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-breakfast",
   "metadata": {},
   "source": [
    "https://sumniya.tistory.com/26 (참고했던 사이트 입니다)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
