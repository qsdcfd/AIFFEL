{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rotary-director",
   "metadata": {},
   "source": [
    "## 논문 톺아보기\n",
    "\n",
    "논문 사이트: https://arxiv.org/pdf/1411.4038.pdf\n",
    "\n",
    "코드 리뷰:[링크텍스트](https://github.com/qsdcfd/AIFFEL/blob/TIL/Personal-Project/Going%20Deeper%20(CV)/Going%20Deeper%2005/GD10%5Dsemantic%20segmentation.Sehyun.ipynb)\n",
    "\n",
    "Semantic Segmentation을 이해하기 위해 가장 근본이 되는 논문이고 도로 영역 맵만들기 실습을 할 때 유용하기에 정리합니다.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 논문 속 핵심 \n",
    "\n",
    "\n",
    "\n",
    "1. Key insight\n",
    "\n",
    ">FCN을 만들기 위해서 input사이즈를 임의로 설정하고 효율적인 추론 및 학습을 통해 알맞은 크기의 출력합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Characteristic\n",
    "\n",
    "*FCN\n",
    "\n",
    ">FCN은 어떤 입력 사이즈가 들어와도 그에 맞는 크기(spatial dimensions)의 출력 이미지를 생산합니다. \n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/1490f87a-bfce-49d0-bf8c-d9253f22bda2/image.png)\n",
    "\n",
    "- 식\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/fa744b42-e4f2-4cc7-ad27-d52556a30d17/image.png)\n",
    "\n",
    "- xij: 데이터의 위치 정보 벡터\n",
    "\n",
    "- yij: 레이어\n",
    "\n",
    "- k: 커널 사이즈\n",
    "\n",
    "- s: stride\n",
    "\n",
    "- fks: layer유형 결정\n",
    "\n",
    "(ex: average pooling, max pooling, activation function,...etc인지를 결정합니다.)\n",
    "\n",
    "- receptive field: 출력 레이어의 뉴런 하나에 영향을 미치는 입력 뉴런들의 공간 크기\n",
    "\n",
    "*FCN특징\n",
    "\n",
    "1. Dense예측을 위해 분류기에 적용\n",
    "\n",
    "- 히트맵을 얻게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/af324759-4c3c-4d7e-841e-e092609edfb6/image.png)\n",
    "\n",
    "2. Patch sampling\n",
    "\n",
    "- Patchwise 훈련은 손실 샘플입니다.\n",
    "\n",
    "   - loss가 빨리 떨어집니다.\n",
    "   \n",
    "   - 전체이미지를 사용하는 것이 더 효율적이라는 결론을 어덱 됩니다. \n",
    "   \n",
    "  \n",
    "![](https://images.velog.io/images/qsdcfd/post/f0b1b648-e9cd-4235-96aa-7f6e0913ecb5/image.png)\n",
    "\n",
    "*FCN의 영역 정의\n",
    "\n",
    "> 지도학습으로 사전 학습된 분류모델과  입력 데이터의 해당 공간 차원을 유지하기 위해 FCN이 적용됩니다.\n",
    "\n",
    "\n",
    "*Skip architecture 적용\n",
    "\n",
    ">추상적인 레이어의 의미적 정보아 shallow and fine의 외적적 정보를 정의한 것으로 정확한 segmentation결과를 얻기 위함입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/7aed334a-09b4-49d7-af1d-b8df8876b055/image.png)\n",
    "\n",
    "왜? 얕은 층과 깊은 층을 합하는 걸까요?\n",
    "\n",
    "- 얕은 층: 직선,곡선,섹상등의 낮은 수준의 특징이 활성화. local feature 감지\n",
    "\n",
    "- 깊은 층: 복잡하고 포괄적인 개체 정보 활성화, global feature감지\n",
    "\n",
    "위의 두 층의 장점을 모두 결합하여 Segmentation의 품질 개선을 합니다.(by Visualizing and Understanding Convolutional Networks Paper)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/ce01132b-6dae-4e02-8c0d-f9101360fbdd/image.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "3. 이미지로 보는 전반적인 FCN의 구조(AlexNet기반)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/2c4a9f13-64bc-4af5-8494-0df019c2d18b/image.png)\n",
    "\n",
    "- 입력 이미지 후 앞의 5개 상자들은 특징 추출하는 구간입니다.\n",
    "\n",
    "- 뒤의 3개 상자들은 FCN을 의미하여 특징이 추출된 것을 분류하는 구간입니다.\n",
    "\n",
    "- Pixelwise prediction은 skip network부분입니다.\n",
    "\n",
    "- 마지막으로 segmentation이 됩니다. \n",
    "\n",
    "<br>\n",
    "\n",
    "4. 결과\n",
    "\n",
    "\n",
    "4. 표를 통한 결과 \n",
    "\n",
    "\n",
    "- Metrics\n",
    "\n",
    "*IoU\n",
    "\n",
    ">객체 인식같은 모델을 사용했을 때 실제 물체의 위치와 예측된 물체의 위치를 평가방법으로 얼마나 일치하는지를 수학적으로 나타내는 지표입니다. \n",
    "\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/404bdf8d-c8bd-41f5-a197-b9ae3ed0ac50/image.png)\n",
    "\n",
    "\n",
    "- PASCAL VOC\n",
    "\n",
    "*아래 식이용\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/715c4baa-07a4-44e9-8690-9297617644af/image.png)\n",
    "\n",
    "\n",
    "*결과\n",
    "![](https://images.velog.io/images/qsdcfd/post/5f1c23fe-36c2-47ac-8872-953ac7f81722/image.png)\n",
    "\n",
    "- NYUDv2\n",
    "\n",
    ">Depth에 대한 정보와 RGB데이터가 같이 들어 있는 결과입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/f2c71854-902b-48d7-bc43-e37f3c696d88/image.png)\n",
    "\n",
    "\n",
    "- SIFT Flow\n",
    "\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/3f5e593f-030a-47e5-80cf-7fe91343fbd1/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-working",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
